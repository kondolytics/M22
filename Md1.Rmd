---
title: "Mariners 2022"
author: "Nicholas Kondo"
subtitle: 
output:
  html_document:
    df_print: paged
    toc: true 
  html_notebook: default
---

```{r setup, include= FALSE}
library(knitr)

# Change the number in set seed to your own favorite number
set.seed(4)
options(width=70)
options(scipen=99)

# this sets text outputted in code chunks to small
opts_chunk$set(tidy.opts=list(width.wrap=50),tidy=TRUE, size = "vsmall")  
opts_chunk$set(message = FALSE,                                          
               warning = FALSE,
               # "caching" stores objects in code chunks and only rewrites if you change things
               cache = TRUE, 
               cache.lazy = FALSE,
               # automatically downloads dependency files
               autodep = TRUE,
               # 
               cache.comments = FALSE,
               # 
               collapse = TRUE,
               # change fig.width and fig.height to change the code height and width by default
               fig.width = 5.5,  
               fig.height = 4.5,
               fig.align='center')
```

```{r setup-2, include= FALSE}

# Always print this out before your assignment
sessionInfo()
getwd()

```

```{r setup-3, include =FALSE}
# Loading libraries and data 

library(here)
library(dplyr)
library(ggplot2)
library(forcats)
library(viridis)
library(randomForest)
library(mgcv)
library(rpart)
library(partykit)
library(pROC)
library(caret)
library(tidymodels)
library(DMwR)
library(ROSE)
library(randomForestExplainer)
library(themis)
library(baguette)
library(naniar)

train <- read.csv(here('Datasets','train.csv'))
```

# Exploratory Data Analysis

This is a very imbalanced data set.  Home Runs occur less than 1% of all pitches.  Let's take a look below on Home Runs across pitch types.

```{r}
train %>%
  filter(!is.na(pitch_type)) %>%
  mutate(pitch_type = fct_lump(pitch_type, prop = 0.05)) %>%
  count(pitch_type, is_hr) %>%
  group_by(pitch_type) %>%
  mutate(percent = scales::percent(n / sum(n))) %>%
  kable(
    col.names = c("Pitch Type", "Is_HR?", "Number of HRs", "% of HRs"),
    align = "llrr")
```

```{r, include = FALSE}
homeruns <- train %>% 
  filter(is_hr == 1)
```

## 1.1 Pitch Location
Let's look at how the location of pitches affects the probability of hitting a home run.  This heat map aligns with our baseball inference that pitches closer to the middle of the zone are more likely to be hit for a home run.  It'd be interesting to look at heat maps for different types of pitches and separately for RHP and LHP and splits based on pitch type.  
```{r}
# Creating generalized model
      fit <- gam(is_hr ~ s(plate_side, plate_height), family = binomial, data = train)
      # Finding predicted probabilities over a 50 x 50 grid
      x <- seq(-1.5, 1.5, length.out=50)
      y <- seq(0.5, 5, length.out=50)
      data.predict <- data.frame(plate_side = c(outer(x, y * 0 + 1)),
                                 plate_height = c(outer(x * 0 + 1, y)))
      # Creating LP model
      lp <- predict(fit, data.predict)
      # Adding the probability of hitting a home run given the location 
      data.predict$Probability <- exp(lp) / (1 + exp(lp))
      # Creating the K Zone
      topKzone <- 3.5
      botKzone <- 1.6
      inKzone <- -0.95
      outKzone <- 0.95
      kZone <- data.frame(
        x=c(inKzone, inKzone, outKzone, outKzone, inKzone),
        y=c(botKzone, topKzone, topKzone, botKzone, botKzone))
      # Constructing the plot for ALL pitchers
      ggplot(kZone, aes(x, y)) +
        geom_tile(data=data.predict, 
                  aes(x= plate_side, y= plate_height, fill= Probability)) +
        scale_fill_distiller(palette = "Spectral") +
        geom_path(lwd=1.5, col="black") +
        coord_fixed() + 
        labs(title = "HR Probability Based on Pitch Location",
             subtitle = "All Pitchers",
             caption = paste("N = ", nrow(train)))
```

## 1.2 Missing Values
Exploring the missing values across the data set.  
```{r}
sort(colSums(is.na(train)))
```

There are a lot of NA values for pitch type... let's check out the different types of pitches.  
```{r}
train$pitch_type <- as.factor(train$pitch_type)
table(train$pitch_type)
```

There are six types of pitches listed in this data set with a majority of pitches being  a fastball, and a low number of knuckle balls.  Here we are going to look at a data set of the pitches where `pitch_type = NA` to understand why these missing values might be occurring.  
```{r}
NA_pitchType <- train %>% 
  filter(is.na(train$pitch_type))
```

# Feature Engineering

The first section of feature engineering will deal with our missing values.  Next, we will normalize horizontal metrics for righties and lefties, followed by a count variable, and a variable that represents the type of matchup.  

## Handling Missing Values

Most models don't allow any missing values.  In this section we are going to take steps to address these missing values, particularly focusing on pitch type and spin rate where we see the most missing data.  
```{r}
gg_miss_upset(train, nsets = 7)
```

The NA values for pitch type seem to be somewhat normal- meaning the pitches weren't spiked in the ground or thrown over the backstop, and some actually were even hit for home run.  We should try to keep this data.  My assumption is that not every pitch can fall under a pitch classification.  For example, we have 6 classes of pitch type: `FA` `CU` `CH` `SL` `SI` and `KN`.  What would we classify a knuckle-curve?  The best way to preseve this data is by implementing an "other" class for all the missing values. 
```{r}
# Creating a new data set and removing ID variables
train1 <- train  %>% 
  select(-date, -umpire_id, -catcher_id,  -inning, -top_bottom, -y55, -pitch_id, -pitcher_id, -batter_id, -tilt, -stadium_id,
         -inning, -outs)
# Changing to character
train1$pitch_type <- as.character(train1$pitch_type)
# Changing NA values to other
train1$pitch_type[is.na(train1$pitch_type)] <- "other"
train1$pitch_type <- as.factor(train1$pitch_type)

# Confirming NA values
sort(colSums(is.na(train1)))
levels(train1$pitch_type)
```

### Spin Rate
To accommodate for spin rate missing values, we are going to impute the median spin rate based on the type of pitch.  To do this first we need to separate the pitches by pitch type, compute the median, then impute the median for the missing values.  
```{r}
# Creating separate data sets for each pitch type 
fastballs <- train1 %>% 
  filter(pitch_type == 'FA')
curveballs <- train1 %>% 
  filter(pitch_type == 'CU')
changeups <- train1 %>% 
  filter(pitch_type == 'CH')
sinkers <- train1 %>% 
  filter(pitch_type == 'SI')
sliders <- train1 %>% 
  filter(pitch_type == 'SL')
knuckleballs <- train1 %>% 
  filter(pitch_type == 'KN')
others <- train1 %>% 
  filter(pitch_type == 'Other')

# Filling all NA spin_rate values with the median spin rate of that respective pitch
fastballs$spin_rate[is.na(fastballs$spin_rate)] <- median(fastballs$spin_rate, na.rm=TRUE)
curveballs$spin_rate[is.na(curveballs$spin_rate)] <- median(curveballs$spin_rate, na.rm=TRUE)
changeups$spin_rate[is.na(changeups$spin_rate)] <- median(changeups$spin_rate, na.rm=TRUE)
sinkers$spin_rate[is.na(sinkers$spin_rate)] <- median(sinkers$spin_rate, na.rm=TRUE)
sliders$spin_rate[is.na(sliders$spin_rate)] <- median(sliders$spin_rate, na.rm=TRUE)
knuckleballs$spin_rate[is.na(knuckleballs$spin_rate)] <- median(knuckleballs$spin_rate, na.rm=TRUE)
others$spin_rate[is.na(others$spin_rate)] <- median(others$spin_rate, na.rm=TRUE)

# Combining our separate data sets back together
train1 <- bind_rows(fastballs, curveballs, changeups, sinkers, sliders, knuckleballs, others)
# Freeing memory
rm(fastballs, curveballs, changeups, sinkers, sliders, knuckleballs, others)

# Checking our NA values again 
sort(colSums(is.na(train1)))
```

### Other Missing/Usual Values
At this stage, we don't have many more missing values.  There are a series of unusual values where `vert_break`, `induced_break`, and `horz_break` have values of 0.0000.  We will remove the remaining unusual and missing values. 
```{r}
# Table of our NA values for break, notice horz_break are missing as well
train1 %>% 
  filter(is.na(vert_break))
# Table that shows our unusual missing values for break 
train1 %>% 
  filter(vert_break == 0)
# Dropping NA values
train1 <- na.omit(train1)
# Dropping rows where break recorded as 0.0000
train1 <-subset(train1, vert_break!= 0)
# Changing strings to factors
train1 <- as.data.frame(unclass(train1),                     
                        stringsAsFactors = TRUE)
# Looking at NA values
sort(colSums(is.na(train1)))
```

## Count Variable

Next let's add a `count` variable.  The reason for this is because each count is unique, and an 0-0 count should be treated differently than an 0-2 count.  Since we will be converting these variable to a dummy variable.  Proper syntax is important so `count00` represents a 0-0 count.  
```{r}
# Creating a count variable 
train1 <- train1 %>% 
  mutate(count = paste("count", balls, strikes, sep = "")) 
train1$count <- as.factor(train1$count) # Changing object to factor

levels(train1$count)
```

## Normalizing Horizontal Movements

```{r}
    train1 <- train1 %>%
      # Release Side
      mutate(rel_side = ifelse(pitcher_side == 'Left', rel_side*(-1), rel_side)) %>% 
      # Horizontal Release Angle
      mutate(horz_release_angle = ifelse(pitcher_side == 'Left', 
                                         horz_release_angle*(-1), horz_release_angle)) %>%
      # Horizontal Break
      mutate(horz_break = ifelse(pitcher_side == 'Left', horz_break*(-1), horz_break)) %>%
      # Horizontal Approach Angle
      mutate(horz_approach_angle = ifelse(pitcher_side == 'Left', horz_approach_angle*(-1),
                                          horz_approach_angle))
```

## Hitter Pitcher Matchup

Is this a Righty-Right matchup?  Righty-Lefty matchup?  
```{r}
# Creating a matchup feature
      # Matchup will indicate the handedness of the matchups
      train1 <- train1 %>% 
              mutate(matchup = 
                       ifelse(pitcher_side == "Right" & batter_side == "Right", 
                              "Righty-Righty",
                       ifelse(pitcher_side == "Right" & batter_side == "Left",
                              "Righty-Lefty",
                       ifelse(pitcher_side == "Right" & batter_side == "Undefine",
                              "Righty-Lefty",
                       ifelse(pitcher_side == "Left" & batter_side == "Left",
                              "Lefty-Lefty",
                       ifelse(pitcher_side == "Left" & batter_side == "Right",
                              "Lefty-Righty",
                       ifelse(pitcher_side == "Left" & batter_side == "Switch",
                              "Lefty-Righty","NA")))))))
      
      train1$matchup <- as.factor(train1$matchup)
      table(train1$matchup)
```

# Model Building 

We are going to build a series of models and evaluate their results.  My first assumption is that non-linear / tree models will perform better than linear models.  This assumption stems from the fact that most metrics need to fall within a certain parameter for the pitch to result in a home run.  For example, a home run pitch needs to fall between a certain height and width.  A home run also needs to fall within a certain vertical and horizontal release and approach angles.  There are not many linear relationships for some of our most important variables, but we will build out both linear and non-linear models and evaluate them.    

## Pre-Processing


```{r}
train1$is_hr <- as.logical(train1$is_hr)

train_df <- train1 %>%
  filter(!is.na(pitch_type)) %>% 
  select(pitcher_side, batter_side, release_speed, vert_release_angle, 
         horz_release_angle, spin_rate, spin_axis, rel_height,
         rel_side, extension, induced_vert_break, horz_break,
         plate_height, plate_side, zone_speed, vert_approach_angle, horz_approach_angle,
         x55, z55, pitch_type, count, matchup, is_hr) %>%
  mutate(is_hr = case_when(
    is_hr ~ "HR",
    TRUE ~ "No HR"
  )) %>%
  mutate_if(is.character, factor) %>%
  mutate_if(is.logical, as.integer)
```

## Splitting

Here we are splitting our data and creating cross validation folds.  
```{r}
set.seed(123)
pitches_split <- initial_split(train_df, strata = is_hr)
pitches_train <- training(pitches_split)
pitches_test <- testing(pitches_split)

set.seed(123)
pitches_folds <- vfold_cv(pitches_train, strata = is_hr)
```

Creating a recipe for our model.  In our recipe we are including a function to change all our factor variables to dummy variables. 
```{r}
pitches_rec <- recipe(is_hr ~ ., data = pitches_train) %>%
  step_dummy(all_nominal(), -is_hr) 

pitches_rec
```
Setting up our models.  We are starting with a logistic regression, bagged-tree model, and a random forest.  The metrics we will collect to evaluate our model are area under the ROC curve, log-loss, accuracy, sensitivity, and specificity.   
```{r}
# Logistic Regression
glm_spec <- logistic_reg() %>%
  set_engine("glm")

# Random Forest
rf_spec <- rand_forest(trees = 1000) %>%
  set_mode("classification") %>%
  set_engine("ranger")

# Bagged Tree Model
bag_spec <-
  bag_tree(min_n = 10) %>%
  set_engine("rpart", times = 25) %>%
  set_mode("classification")

# Add recipe to the workflow
pitches_wf <- workflow() %>%
  add_recipe(pitches_rec)

# Specifying the metrics to be collected
pitches_metrics <- metric_set(roc_auc, mn_log_loss, accuracy, sensitivity, specificity)
```

## Logistic Regression Model
```{r}
# Linear Model
doParallel::registerDoParallel()
glm_rs <- pitches_wf %>%
  add_model(glm_spec) %>%
  fit_resamples(
    resamples = pitches_folds,
    metrics = pitches_metrics,
    control = control_resamples(save_pred = TRUE)
  )

collect_metrics(glm_rs)
```

## Bagged Tree
```{r}
# Bagged Tree Model
doParallel::registerDoParallel()
bag_rs <- pitches_wf %>%
  add_model(bag_spec) %>%
  fit_resamples(
    resamples = pitches_folds,
    metrics = pitches_metrics,
    control = control_resamples(save_pred = TRUE)
  )

collect_metrics(bag_rs)
```

## Random Forest Tree
```{r}
# Random Forest Model
doParallel::registerDoParallel()
rf_rs <- pitches_wf %>%
  add_model(rf_spec) %>%
  fit_resamples(
    resamples = pitches_folds,
    metrics = pitches_metrics,
    control = control_resamples(save_pred = TRUE)
  )

collect_metrics(rf_rs)
```

# Resampling

After evaluating our models we can see the effect of the imbalance in our response variable.  A few techniques will be used to address this where we can find a balance of specificity and sensitivity.  We will look at techniques such as up-sampling, down-sampling, and hybrid algorithms such as SMOTE and ROSE.  

## Down-sampling
The first resampling technique we will use is down-sampling.  Down sampling is where we randomly subset all the classes in the training set so that their class frequencies match the minority class.  This would result in using only 2% of our training data being used to fit the mode.  
```{r}
# Creating our recipe for down sampling
pitches_rec <- recipe(is_hr ~ ., data = pitches_train) %>%
  step_dummy(all_nominal(), -is_hr) %>% 
  step_downsample(is_hr)

# Logistic Regression
glm_spec <- logistic_reg() %>%
  set_engine("glm")

# Random Forest
rf_spec <- rand_forest(trees = 1000) %>%
  set_mode("classification") %>%
  set_engine("ranger")

# Bagged Tree Model
bag_spec <-
  bag_tree(min_n = 10) %>%
  set_engine("rpart", times = 25) %>%
  set_mode("classification")

# Add recipe to the workflow
pitches_wf <- workflow() %>%
  add_recipe(pitches_rec)

# Specifying the metrics to be collected
pitches_metrics <- metric_set(roc_auc, mn_log_loss, accuracy, sensitivity, specificity)
```

# Add recipe to the workflow
pitches_wf <- workflow() %>%
  add_recipe(pitches_rec)
```

### Logistic Regression
```{r}
# Linear Model
doParallel::registerDoParallel()
glm_rs <- pitches_wf %>%
  add_model(glm_spec) %>%
  fit_resamples(
    resamples = pitches_folds,
    metrics = pitches_metrics,
    control = control_resamples(save_pred = TRUE)
  )

collect_metrics(glm_rs)
```

### Bagged Tree
```{r}
# Bagged Tree Model
doParallel::registerDoParallel()
bag_rs <- pitches_wf %>%
  add_model(bag_spec) %>%
  fit_resamples(
    resamples = pitches_folds,
    metrics = pitches_metrics,
    control = control_resamples(save_pred = TRUE)
  )

collect_metrics(bag_rs)
```

### Random Forest
```{r}
# Random Forest Model
doParallel::registerDoParallel()
rf_rs <- pitches_wf %>%
  add_model(rf_spec) %>%
  fit_resamples(
    resamples = pitches_folds,
    metrics = pitches_metrics,
    control = control_resamples(save_pred = TRUE)
  )

collect_metrics(rf_rs)
```

## Up-sampling

The next resampling method is up-sampling.  Up-sampling randomly samples the rare-occurring class to be the same size as the majority class.  In other words, we will now have the same amount of home runs as non-home runs.  

```{r}
# Creating our recipe for upsampling
pitches_rec <- recipe(is_hr ~ ., data = pitches_train) %>%
  step_dummy(all_nominal(), -is_hr) %>% 
  step_upsample(is_hr)

# Add recipe to the workflow
pitches_wf <- workflow() %>%
  add_recipe(pitches_rec)
```

### Logistic Regression
```{r}
# Linear Model
doParallel::registerDoParallel()
glm_rs <- pitches_wf %>%
  add_model(glm_spec) %>%
  fit_resamples(
    resamples = pitches_folds,
    metrics = pitches_metrics,
    control = control_resamples(save_pred = TRUE)
  )

collect_metrics(glm_rs)
```

### Bagged Tree
```{r}
# Bagged Tree Model
doParallel::registerDoParallel()
bag_rs <- pitches_wf %>%
  add_model(bag_spec) %>%
  fit_resamples(
    resamples = pitches_folds,
    metrics = pitches_metrics,
    control = control_resamples(save_pred = TRUE)
  )

collect_metrics(bag_rs)
```

### Random Forest

To save computational time and memory, the results of this random forest will not be shown here, but we can expect similar results to the bagged tree model.  

## SMOTE

SMOTE stands for *synthetic minority over-sampling technique.  This technique synthesizes new occurrences of home runs from the existing examples. 
```{r}
# Creating our recipe 
pitches_rec <- recipe(is_hr ~ ., data = pitches_train) %>%
  step_dummy(all_nominal(), -is_hr) %>% 
  step_smote(is_hr)

# Add recipe to the workflow
pitches_wf <- workflow() %>%
  add_recipe(pitches_rec)
```

### Logistic Regression
```{r}
# Linear Model
doParallel::registerDoParallel()
glm_rs <- pitches_wf %>%
  add_model(glm_spec) %>%
  fit_resamples(
    resamples = pitches_folds,
    metrics = pitches_metrics,
    control = control_resamples(save_pred = TRUE)
  )

collect_metrics(glm_rs)
```

### Bagged Tree
```{r}
# Bagged Tree Model
doParallel::registerDoParallel()
bag_rs <- pitches_wf %>%
  add_model(bag_spec) %>%
  fit_resamples(
    resamples = pitches_folds,
    metrics = pitches_metrics,
    control = control_resamples(save_pred = TRUE)
  )

collect_metrics(bag_rs)
```

### Random Forest

To save computational time and memory, the results of this random forest will not be shown here, but the results were very similar to the bagged tree model.  

## ROSE

ROSE stands for random over-sampling examples and is a bootstrap-based technique to help deal with the imbalanced classes.  For our tree models, we see unusual resuls where the model's sensitivity results in 1 and the specificity is equal to 0.  The result is an extremely high log loss score as the model predicts home run for every outcome.  
```{r}
# Creating our recipe 
pitches_rec <- recipe(is_hr ~ ., data = pitches_train) %>%
  step_dummy(all_nominal(), -is_hr) %>% 
  step_rose(is_hr)

# Add recipe to the workflow
pitches_wf <- workflow() %>%
  add_recipe(pitches_rec)
```

### Logistic Regression
```{r}
# Linear Model
doParallel::registerDoParallel()
glm_rs <- pitches_wf %>%
  add_model(glm_spec) %>%
  fit_resamples(
    resamples = pitches_folds,
    metrics = pitches_metrics,
    control = control_resamples(save_pred = TRUE)
  )

collect_metrics(glm_rs)
```

### Bagged Tree
```{r}
# Bagged Tree Model
doParallel::registerDoParallel()
bag_rs <- pitches_wf %>%
  add_model(bag_spec) %>%
  fit_resamples(
    resamples = pitches_folds,
    metrics = pitches_metrics,
    control = control_resamples(save_pred = TRUE)
  )

collect_metrics(bag_rs)
```

### Random Forest

To save computational time and memory, the results of this random forest will not be shown here, but the results were very similar to the bagged tree model. 

## Resampling Part 2

In this previous series of models, we might have better recall and precision, but we are seeing lower log-loss scores because when we do things like over-sample, we are creating equal balanced class so that home runs occur 50% of the time.  When we apply this model to our test data, we generate overly optimistic probabilities that do not truly represent in 'real life'.  To find a balance between overly optimistic predictions and an imbalanced data set, we will do another round of resampling.  This time we will use the same techniques such as down-sampling, up-sampling, SMOTE and ROSE, but instead set a ratio for our classes.  This will be explained further in each technique.

## Down Sampling 

We will down-sample our data again and reduce the amount of 'non-home-run' data points.  Rather than setting the imbalanced classes to equal each other.  We will remove data points from the majority class to where the minority class will have a 1:2 ratio to the majority class.  In other words, we will have 1 home run for every 2 non-home runs.  We are still going to produce overly optimistic probabilities, but not to the extent as 1:1 resampling, and we will have enough data to balance our precision and recall curves.
```{r}
# Creating our recipe 
pitches_rec <- recipe(is_hr ~ ., data = pitches_train) %>%
  step_dummy(all_nominal(), -is_hr) %>% 
  step_downsample(is_hr, under_ratio = 2.5)

# Add recipe to the workflow
pitches_wf <- workflow() %>%
  add_recipe(pitches_rec)
```

### Logistic Regression
```{r}
# Linear Model
doParallel::registerDoParallel()
glm_rs <- pitches_wf %>%
  add_model(glm_spec) %>%
  fit_resamples(
    resamples = pitches_folds,
    metrics = pitches_metrics,
    control = control_resamples(save_pred = TRUE)
  )

collect_metrics(glm_rs)
```

### Bagged Tree
```{r}
# Bagged Tree Model
doParallel::registerDoParallel()
bag_rs <- pitches_wf %>%
  add_model(bag_spec) %>%
  fit_resamples(
    resamples = pitches_folds,
    metrics = pitches_metrics,
    control = control_resamples(save_pred = TRUE)
  )

collect_metrics(bag_rs)
```

### Random Forest
```{r}
# Random Forest Model
doParallel::registerDoParallel()
rf_rs <- pitches_wf %>%
  add_model(rf_spec) %>%
  fit_resamples(
    resamples = pitches_folds,
    metrics = pitches_metrics,
    control = control_resamples(save_pred = TRUE)
  )

collect_metrics(rf_rs)
```


## Upsample

```{r}
# Creating our recipe 
pitches_rec <- recipe(is_hr ~ ., data = pitches_train) %>%
  step_dummy(all_nominal(), -is_hr) %>% 
  step_upsample(is_hr, over_ratio = .5)

# Add recipe to the workflow
pitches_wf <- workflow() %>%
  add_recipe(pitches_rec)
```

### Logistic Regression
```{r}
# Linear Model
doParallel::registerDoParallel()
glm_rs <- pitches_wf %>%
  add_model(glm_spec) %>%
  fit_resamples(
    resamples = pitches_folds,
    metrics = pitches_metrics,
    control = control_resamples(save_pred = TRUE)
  )

collect_metrics(glm_rs)
```

### Bagged Tree
```{r}
# Bagged Tree Model
doParallel::registerDoParallel()
bag_rs <- pitches_wf %>%
  add_model(bag_spec) %>%
  fit_resamples(
    resamples = pitches_folds,
    metrics = pitches_metrics,
    control = control_resamples(save_pred = TRUE)
  )

collect_metrics(bag_rs)
```

### Random Forest

To save computational time and memory, the results of this random forest will not be shown here, but the results were very similar to the bagged tree model. 

## SMOTE RATIO

We will only look at logistic regression for this model because we saw ur tree models have extremely low sensitivity in SMOTE for a 1:1 ratio.  We can only expect the sensitivity to get worse as we add more non-home runs in the data set.
```{r}
# Creating our recipe 
pitches_rec <- recipe(is_hr ~ ., data = pitches_train) %>%
  step_dummy(all_nominal(), -is_hr) %>% 
  step_smote(is_hr, over_ratio = .5)

# Add recipe to the workflow
pitches_wf <- workflow() %>%
  add_recipe(pitches_rec)
```

### Logistic Regression
```{r}
# Linear Model
doParallel::registerDoParallel()
glm_rs <- pitches_wf %>%
  add_model(glm_spec) %>%
  fit_resamples(
    resamples = pitches_folds,
    metrics = pitches_metrics,
    control = control_resamples(save_pred = TRUE)
  )

collect_metrics(glm_rs)
```

##  ROSE Ratio

We continue to see a 1.0 sensitivity and 0.0 specificity in our tree models even as we continue to change the ratio.  ROSE will no longer be tested any further.    
```{r}
# Creating our recipe 
pitches_rec <- recipe(is_hr ~ ., data = pitches_train) %>%
  step_dummy(all_nominal(), -is_hr) %>% 
  step_rose(is_hr,
            )

# Add recipe to the workflow
pitches_wf <- workflow() %>%
  add_recipe(pitches_rec)
```

### Logistic Regression
```{r}
# Linear Model
doParallel::registerDoParallel()
glm_rs <- pitches_wf %>%
  add_model(glm_spec) %>%
  fit_resamples(
    resamples = pitches_folds,
    metrics = pitches_metrics,
    control = control_resamples(save_pred = TRUE)
  )

collect_metrics(glm_rs)
```

### Bagged Tree
```{r}
# Bagged Tree Model
doParallel::registerDoParallel()
bag_rs <- pitches_wf %>%
  add_model(bag_spec) %>%
  fit_resamples(
    resamples = pitches_folds,
    metrics = pitches_metrics,
    control = control_resamples(save_pred = TRUE)
  )

collect_metrics(bag_rs)
```

# Evaluation 

After running a series of models, a series of resampling techniques, and tuning the models by changing ratios, we can conclude that our best resampling technique will be down-sampling.  To fine-tune this further, I continued to add non-home run data points by changing the ratio, and increased the ratio to include as many non-home-runs as possible without affecting the specificity and sensitivity.  

This model is being evaluated on log loss score.  Although the log loss scored actually increased from the initial model, I would argue this is a much useful model.  A model that predicts no home run in every occurrence might be 99% accurate with a extremely low log-loss score but does not provide any use about our variables or what leads to home runs.  There is a tradeoff in accuracy and having optimal sensitivity and specificity.  

# Final Model

The final model is a bagged tree model that was produced from a down-sampling technique with a 2.5:1 ratio of HR:No_HR.  Here are the results.

```{r}
# Creating our recipe 
pitches_rec <- recipe(is_hr ~ ., data = pitches_train) %>%
  step_dummy(all_nominal(), -is_hr) %>% 
  step_downsample(is_hr, under_ratio = 2.5)

# Add recipe to the workflow
pitches_wf <- workflow() %>%
  add_recipe(pitches_rec)

# Bagged Tree Model
doParallel::registerDoParallel()
bag_rs_final <- pitches_wf %>%
  add_model(bag_spec) %>%
  fit_resamples(
    resamples = pitches_folds,
    metrics = pitches_metrics,
    control = control_resamples(save_pred = TRUE)
  )

collect_metrics(bag_rs_final)
```

As shown below and with no surprise, the most important variables in predicting a home run were `plate_side` and `plate_height`.  In other words, the location is the most important variable followed by vertical release angle, release speed, vertical approach angle, induced vertical break, and horizontal release angle.  
```{r}
final_wf <- workflow() %>% 
  add_recipe(pitches_rec) %>% 
  add_model(bag_spec)

final_modelfit <- fit(final_wf, train_df)

final_modelfit
```

Looking at the predictions against our other split.  
```{r}
preds <- predict(final_modelfit, pitches_test, type = 'prob')

preds <- bind_cols(pitches_test, preds)
```

Downloading the train dataset and printing the predictions on the original test set (test set that doesn't show outcome)
```{r, include = FALSE}
library(writexl, include = FALSE)

test <- read.csv(here('Datasets','test.csv'))

# Pre-process

# Creating a count variable 
test <- test %>% 
  mutate(count = paste("count", balls, strikes, sep = "")) 
test$count <- as.factor(test$count) # Changing object to factor

    test <- test %>%
      # Release Side
      mutate(rel_side = ifelse(pitcher_side == 'Left', rel_side*(-1), rel_side)) %>% 
      # Horizontal Release Angle
      mutate(horz_release_angle = ifelse(pitcher_side == 'Left', 
                                         horz_release_angle*(-1), horz_release_angle)) %>%
      # Horizontal Break
      mutate(horz_break = ifelse(pitcher_side == 'Left', horz_break*(-1), horz_break)) %>%
      # Horizontal Approach Angle
      mutate(horz_approach_angle = ifelse(pitcher_side == 'Left', horz_approach_angle*(-1),
                                          horz_approach_angle))

 # Creating a matchup feature
      # Matchup will indicate the handedness of the matchups
      test <- test %>% 
              mutate(matchup = 
                       ifelse(pitcher_side == "Right" & batter_side == "Right", 
                              "Righty-Righty",
                       ifelse(pitcher_side == "Right" & batter_side == "Left",
                              "Righty-Lefty",
                       ifelse(pitcher_side == "Right" & batter_side == "Undefine",
                              "Righty-Lefty",
                       ifelse(pitcher_side == "Left" & batter_side == "Left",
                              "Lefty-Lefty",
                       ifelse(pitcher_side == "Left" & batter_side == "Right",
                              "Lefty-Righty",
                       ifelse(pitcher_side == "Left" & batter_side == "Switch",
                              "Lefty-Righty","NA")))))))
      test$matchup <- as.factor(test$matchup)
```

```{r}
preds <- predict(final_modelfit, new_data = test, type = 'prob')
preds <- test %>% 
  bind_cols(preds) %>% 
  select(pitch_id, .pred_HR)
```
